#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Summarize papers with Qwen and build a markdown digest.
Usage:
  python scripts/summarize_qwen.py --date 2025-08-11 --limit 20
Requires:
  - env QWEN_API_KEY  (set via GitHub Actions secret)
"""
import os, json, argparse, time, sys
from datetime import datetime
from typing import List, Dict
import requests

DATA_PATH = os.path.join(os.path.dirname(__file__), "../data/arxiv.json")
OUT_DIR   = os.path.join(os.path.dirname(__file__), "../digests")
os.makedirs(OUT_DIR, exist_ok=True)

QWEN_API_KEY = os.getenv("QWEN_API_KEY", "").strip()
# é‡‡ç”¨ OpenAI å…¼å®¹æ¥å£ï¼ˆDashScope Compatible Modeï¼‰
BASE_URL = os.getenv(
    "QWEN_COMPAT_URL",
    "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
)
MODEL = os.getenv("QWEN_MODEL", "qwen-plus")  # ä¹Ÿå¯ç”¨ qwen2.5 ç­‰

SYS_PROMPT = (
    "ä½ æ˜¯èµ„æ·±ç§‘ç ”åŠ©ç†ã€‚è¯·æ ¹æ®ç»™å®šçš„è®ºæ–‡æ ‡é¢˜ã€ä½œè€…ã€æ‘˜è¦ï¼Œ"
    "è¾“å‡ºç»“æ„åŒ–è¦ç‚¹ï¼Œä½¿ç”¨ä¸­æ–‡ï¼š\n"
    "1) ç ”ç©¶é—®é¢˜ä¸èƒŒæ™¯ï¼ˆ2-3è¡Œï¼‰\n"
    "2) æ–¹æ³•æ¡†æ¶ï¼ˆæ¡ç›®åŒ–ï¼Œæœ¯è¯­æ ‡å‡†åŒ–ï¼‰\n"
    "3) å…³é”®ç»“æœï¼ˆå°½é‡ä¿ç•™å®šé‡æŒ‡æ ‡ï¼‰\n"
    "4) å±€é™æ€§ä¸å¨èƒï¼ˆ>=2ç‚¹ï¼‰\n"
    "5) å¤ç°çº¿ç´¢ï¼ˆæ•°æ®/ä»£ç /è¶…å‚ï¼Œå¦‚æ— å†™â€œæœªç»™å‡ºâ€ï¼‰\n"
    "6) ä¸‰è¡Œç”µæ¢¯æ¼”è®²ï¼ˆ<= 200å­—ï¼‰\n"
    "åªè¿”å› Markdown å†…å®¹ï¼Œä¸è¦é¢å¤–å¯’æš„ã€‚"
)

def call_qwen(title: str, authors: str, summary: str, link: str) -> str:
    if not QWEN_API_KEY:
        return "_ï¼ˆæœªé…ç½® QWEN_API_KEYï¼Œè·³è¿‡æ¨¡å‹æ‘˜è¦ï¼‰_"
    headers = {
        "Authorization": f"Bearer {QWEN_API_KEY}",
        "Content-Type": "application/json",
    }
    user = (
        f"ã€é¢˜ç›®ã€‘{title}\n"
        f"ã€ä½œè€…ã€‘{authors}\n"
        f"ã€é“¾æ¥ã€‘{link}\n"
        f"ã€æ‘˜è¦ã€‘{summary}\n"
    )
    data = {
        "model": MODEL,
        "messages": [
            {"role": "system", "content": SYS_PROMPT},
            {"role": "user", "content": user},
        ],
        "temperature": 0.2,
    }
    for attempt in range(3):
        try:
            resp = requests.post(BASE_URL, headers=headers, json=data, timeout=60)
            if resp.status_code == 200:
                js = resp.json()
                # OpenAI å…¼å®¹æ ¼å¼
                content = js["choices"][0]["message"]["content"].strip()
                return content
            elif resp.status_code in (429, 500, 502, 503, 504):
                time.sleep(2 * (attempt + 1))
            else:
                return f"_Qwen è°ƒç”¨å¤±è´¥ï¼ˆHTTP {resp.status_code}ï¼‰ï¼š{resp.text[:200]}_"
        except Exception as e:
            time.sleep(2 * (attempt + 1))
    return "_Qwen è°ƒç”¨å¤±è´¥ï¼ˆå¤šæ¬¡é‡è¯•ä»å¤±è´¥ï¼‰_"

def load_papers(limit: int) -> List[Dict]:
    with open(DATA_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)
    items = []
    for topic, lst in data.items():
        for p in lst:
            items.append({**p, "topic": topic})
    # ç®€å•æŒ‰å‘å¸ƒæ—¶é—´é™åºï¼ˆå·²æ˜¯æœ€æ–°ï¼‰ï¼Œæˆªæ–­
    return items[:limit]

def build_md(date_str: str, items: List[Dict]) -> str:
    lines = [f"# ğŸ“š Daily Paper Digest â€” {date_str}", ""]
    # æŒ‰ topic åˆ†ç»„å±•ç¤º
    from collections import defaultdict
    groups = defaultdict(list)
    for it in items:
        groups[it.get("topic", "misc")].append(it)
    for topic in sorted(groups.keys()):
        lines.append(f"## {topic}")
        for idx, p in enumerate(groups[topic], 1):
            lines.append(f"### {idx}. {p['title']}")
            if p.get("authors"):
                lines.append(f"- Authors: {p['authors']}")
            lines.append(f"- Published: {p.get('published','')}")
            lines.append(f"- Link: {p['link']}\n")
            # åŸæ‘˜è¦ï¼ˆè£å‰ªï¼‰
            short = (p.get("summary","").strip() or "")[:600]
            if short:
                lines.append("**Abstract (truncated)**")
                lines.append(short)
                lines.append("")
            # Qwen æ‘˜è¦
            lines.append("**Qwen Summary**")
            lines.append(p.get("_qwen", "_(no summary)_"))
            lines.append("\n---\n")
    return "\n".join(lines).strip() + "\n"

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--date", default=datetime.utcnow().strftime("%Y-%m-%d"))
    ap.add_argument("--limit", type=int, default=30, help="æœ€å¤šå¤„ç†å¤šå°‘ç¯‡")
    args = ap.parse_args()

    papers = load_papers(args.limit)
    # é€ç¯‡è°ƒç”¨ Qwen
    for i, p in enumerate(papers, 1):
        print(f"[{i}/{len(papers)}] {p['title'][:60]} ...")
        p["_qwen"] = call_qwen(
            title=p["title"],
            authors=p.get("authors", ""),
            summary=p.get("summary", ""),
            link=p["link"],
        )
        # è½»å¾®èŠ‚æµ
        time.sleep(0.3)

    md = build_md(args.date, papers)
    out_path = os.path.join(OUT_DIR, f"digest_{args.date}.md")
    with open(out_path, "w", encoding="utf-8") as f:
        f.write(md)
    print(f"[OK] Wrote {out_path}")

if __name__ == "__main__":
    main()
